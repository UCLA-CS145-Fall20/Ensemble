import pandas as pdfrom Utilities.extractor import get_state_ndays_data,stack_state_ndays_data, STATE_NAME, state_num, state_weightfrom scipy.optimize import nnlsimport numpy as npfrom Utilities.losses import MAPELossimport torch as nnfaulted_state_list = ["West Virginia", "Arkansas", "Idaho", "Oklahoma", "South Carolina",                      "Kansas", "North Dakota", "Hawaii", "Iowa", "South Dakota"]class Ensemble_model:    def __init__(self, input_dict, output_dict):        # self.model_list = model_list        self.confirm_weight = []        self.death_weight = []        for state_name in STATE_NAME:            self.confirm_weight.append(nnls(input_dict[state_name]["Confirmed"],                                            output_dict[state_name]["Confirmed"])[0].reshape(3,1))            self.death_weight.append(nnls(input_dict[state_name]["Deaths"],                                          output_dict[state_name]["Deaths"])[0].reshape(3,1))        self.confirm_weight = np.hstack(self.confirm_weight)        self.death_weight = np.hstack(self.death_weight)        for i in state_num.keys():            preferred_model = state_num[i]            self.confirm_weight[preferred_model, i] = 1            self.death_weight[preferred_model, i] = 1            for other_index in [0, 1, 2]:                if other_index != preferred_model:                    self.confirm_weight[other_index, i] = 0                    self.death_weight[other_index, i] = 0    def loss(self, input, ndays, target):        return MAPELoss(self.predict_confirm(input, ndays).reshape(-1), target)    def predict_confirm(self, X, ndays):        for i in state_weight.keys():            self.confirm_weight[:, i] = self.confirm_weight[:, i] * state_weight[i]        assert(X.shape[0] == ndays * 50)        assert(X.shape[1] == 3)        ndays_res = []        for i in range(ndays):            daily_fifty_states = X[i*50:(i+1)*50, :]            daily_res = np.diag((daily_fifty_states @ self.confirm_weight)).reshape(50,1)            ndays_res.append(daily_res)        return np.vstack(ndays_res).astype("int32")    def predict_death(self, X, ndays):        assert(X.shape[0] == ndays * 50)        assert(X.shape[1] == 3)        ndays_res = []        for i in range(ndays):            daily_fifty_states = X[i*50:(i+1)*50, :]            daily_res = np.diag((daily_fifty_states @ self.death_weight)).reshape(50,1)            ndays_res.append(daily_res)        return np.vstack(ndays_res).astype("int32")    def normalize_weight(self):        conf_col_sum = np.sum(self.confirm_weight, axis=0).T        self.confirm_weight = self.confirm_weight / conf_col_sum        death_col_sum = np.sum(self.death_weight, axis=0).T        self.death_weight = self.death_weight / death_col_sum        print(self.confirm_weight)        print(self.death_weight)if __name__ == '__main__':    validation_1 = pd.read_csv('outputs/update_validation/validation_output1.csv')    validation_2 = pd.read_csv('outputs/update_validation/validation.csv')    validation_3 = pd.read_csv('outputs/update_validation/validation_output3.csv')    # print(validation_3)    # validation_1 = pd.read_csv('outputs/26_validation/validation1.csv')    # validation_2 = pd.read_csv('outputs/26_validation/validation.csv')    # validation_3 = pd.read_csv('outputs/26_validation/validation3.csv')    ndays = 7    # make 50 matrices, each of size train_day * model_len, (7 * 3 in our case)    input_dict = {}    df = pd.read_csv('Utilities/data/train.csv')    output_dict = {}    for i, state_name in enumerate(STATE_NAME):        # please hardcode the shape        confirmed_1 = validation_1["Confirmed"][validation_1["ForecastID"] % 50 == i].to_numpy().reshape(ndays,1)        confirmed_2 = validation_2["Confirmed"][validation_2["ForecastID"] % 50 == i].to_numpy().reshape(ndays,1)        confirmed_3 = validation_3["Confirmed"][validation_3["ForecastID"] % 50 == i].to_numpy().reshape(ndays,1)        d_1 = validation_1["Deaths"][validation_1["ForecastID"] % 50 == i].to_numpy().reshape(ndays, 1)        d_2 = validation_2["Deaths"][validation_2["ForecastID"] % 50 == i].to_numpy().reshape(ndays, 1)        d_3 = validation_3["Deaths"][validation_3["ForecastID"] % 50 == i].to_numpy().reshape(ndays, 1)        input_dict[state_name] = {"Confirmed": np.hstack([confirmed_1, confirmed_2, confirmed_3]),                                  "Deaths": np.hstack([d_1, d_2, d_3])}        train_set = get_state_ndays_data(df, state_name, '08-25-2020', '08-31-2020')        gt_confirmed = train_set["Confirmed"]        gt_death = train_set["Deaths"]        output_dict[state_name] = {"Confirmed": gt_confirmed, "Deaths" : gt_death}    # print("input_dict {}".format(input_dict))    test_dict = {}    model = Ensemble_model(input_dict, output_dict)    model.normalize_weight()    # MAPE training loss    stacked_confirmed_input = np.hstack([validation_1["Confirmed"].to_numpy().reshape(-1, 1),                                         validation_2["Confirmed"].to_numpy().reshape(-1, 1),                                         validation_3["Confirmed"].to_numpy().reshape(-1, 1)])    output_confirmed_data = stack_state_ndays_data(df, STATE_NAME,'08-25-2020', '08-31-2020',                                                                                 False)["Confirmed"].to_numpy()    output_formated_confirm_data = np.zeros(ndays * 50)    for i, state_name in enumerate(STATE_NAME):        for j in range(ndays):            output_formated_confirm_data[j * 50 + i] = output_confirmed_data[i * ndays + j]    confirm_loss = model.loss(stacked_confirmed_input, ndays, output_formated_confirm_data)    print("confirm_loss {}".format(confirm_loss))    stacked_death_input = np.hstack([validation_1["Deaths"].to_numpy().reshape(-1, 1),                                         validation_2["Deaths"].to_numpy().reshape(-1, 1),                                         validation_3["Deaths"].to_numpy().reshape(-1, 1)])    output_death_data = stack_state_ndays_data(df, STATE_NAME,'08-25-2020', '08-31-2020',                                                                                 False)["Deaths"].to_numpy()    output_formated_death_data = np.zeros(ndays * 50)    for i, state_name in enumerate(STATE_NAME):        for j in range(ndays):            output_formated_death_data[j * 50 + i] = output_death_data[i * ndays + j]    death_loss = model.loss(stacked_death_input, ndays, output_formated_death_data)    print("death_loss {}".format(death_loss))    # testing    test1 = pd.read_csv("outputs/update_sub/output1.csv")    test2 = pd.read_csv("outputs/update_sub/output.csv")    test3 = pd.read_csv("outputs/update_sub/output3.csv")    test_confirm = np.hstack([test1["Confirmed"].to_numpy().reshape(-1, 1),                              test2["Confirmed"].to_numpy().reshape(-1, 1),                              test3["Confirmed"].to_numpy().reshape(-1, 1)])    test_confirm_output = model.predict_confirm(test_confirm, 26)    test_death = np.hstack([test1["Deaths"].to_numpy().reshape(-1, 1),                              test2["Deaths"].to_numpy().reshape(-1, 1),                              test3["Deaths"].to_numpy().reshape(-1, 1)])    test_death_output = model.predict_death(test_death, 26)    new_test_output = test1    new_test_output["Confirmed"] = test_confirm_output    new_test_output["Deaths"] = test_death_output    new_test_output.to_csv("combined_output.csv", index=False)